# jemdoc: menu{MENU}{research.html}
= Selected Projects

== Integrated planning and control in the presence of nonlinear and uncertain dynamics
Motion planning and tracking control for robotic and autonomous systems with nonlinear, underactuated and uncertain dynamics – with guaranteed safety – remains a challenging problem. In this project, we developed tracking controllers with transient performance guarantees for general nonlinear systems subject to model uncertainties. The tracking controllers can be conveniently incorporated into a feedback motion planning framework for planning safety-guaranteed trajectories. Our methods are based on control contraction metrics (CCMs) recently proposed for the synthesis of nonlinear controllers using convex optimization. Our specific contributions are as follows.
- For nonlinear systems subject to bounded disturbances, we proposed robust CCMs that minimize the effect of disturbances on nominal-actual trajectory deviations while yielding certificate tubes for quantifying the deviations for both states and inputs,
- For nonlinear systems subject to matched (time- and state-dependent) uncertainties, we proposed a disturbance estimation-based CCM controller that ensures exponential convergence of the actual state trajectory to its nominal counterpart in the presence of matched uncertainties.
~~~
{}{raw}
<iframe width="560" height="315" src="https://www.youtube.com/embed/mrN5iQo7NxE" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
~~~
References
- P. Zhao, A. Lakshmanan, K. Ackerman, A. Gahlawat, M. Pavone, and N. Hovakimyan. Tube-certified trajectory tracking for nonlinear systems with robust control contraction metrics. /IEEE Robotics and Automation Letters/, 7(2): 5528-5535, 2022. 
- P. Zhao, Z. Guo, and N. Hovakimyan. Robust nonlinear tracking control with exponential convergence using contraction metrics and disturbance estimation. /Sensors/, 22(13): 4743, 2022.


== Safe and robust learning-enabled control via active uncertainty compensation
In this project, we explore the integration of machine learning (ML) and control theory for safe and robust learning-enabled control. In particular, we are interested in leveraging adaptive or disturbance observer-based control to /actively compensate for the uncertainties/ that may be induced by environmental change (in a model-free setting) or the inaccuracy of the learned dynamics (in a model-based setting).  This uncertain compensation based approach enables fast reaction to sudden dynamics change and less conservative control performance in the presence of a poorly learned dynamics model compared to robust approaches without uncertainty compensation. Our specific contributions are as follows.
- We proposed an add-on scheme based on adaptive augmentation to improve the robustness of reinforcement learning policies trained in standard ways (e.g., without using robust or adversarial training)
- For linear systems subject to matched state-dependent uncertainties, we integrated an $\mathcal L_1$ adaptive controller and Bayesian learning to ensure the tracking performance while being able to learn state-dependent uncertainties (without needing a parametric structure), for linear nominal systems.
- For nonlinear systems subject to matched state-dependent uncertainties, we proposed an approach for trajectory-centric learning control based on CCM and disturbance estimation. The approach allows for the use of a broad class of model learning tools, including deep neural networks (DNNs), to learn uncertain dynamics while still providing guarantees of transient tracking performance throughout the learning phase. 
~~~
{}{raw}
<iframe width="560" height="315" src="https://www.youtube.com/embed/YQTeHPXmLGM" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
~~~
References 
- Y. Cheng\*, P. Zhao\*, F. Wang, D. J. Block, and N. Hovakimyan. Improving the robustness of reinforcement learning policies with $\mathcal L_1$ adaptive control. /IEEE Robotics and Automation Letters/,
in press, 2022. arXiv:2112.01953.
- Y. Cheng\*, P. Zhao\*, M. Gandhi, B. Li, E. Theodorou and N. Hovakimyan. Robustifying reinforcement learning policies with L1 adaptive control, in /ICRA Workshop on Safe Robot Control with Learned Motion and Environment Models/, 2021. 
- P. Zhao, Z. Guo, Y. Cheng, A. Gahlawat, H. Kang and N. Hovakimyan. Guaranteed nonlinear
tracking in the presence of DNN-learned dynamics with contraction metrics and disturbance
estimation. Submitted to the /2023 American Control Conference/, 2022.
- A. Gahlawat, P. Zhao, A. Patterson, N. Hovakimyan and E. A. Theodorou. L1-GP: L1 adaptive
control with Bayesian learning. /2nd Conference on Learning for Dynamics and Control/, 2020.


== Adaptive geometric control of quadrotors
Quadrotors have been widely used in various applications such as environment monitoring, structure inspection, emergency response, and package delivery. Precise control of quadrotors is very challenging in the presence of model uncertainties and disturbances from various sources, such as aerodynamic drag, unknown payload, and wind/gust.  In this project, we proposed an adaptive geometric controller based on $\mathcal L_1$ adaptive augmentation of a geometric controller, which provides guaranteed tracking performance in the presence of a broad class of uncertainties. We experimentally validated the performance of the controller on a custom-built quadrotor platform. 
~~~
{}{raw}
<iframe width="560" height="315" src="https://www.youtube.com/embed/18-2OqTRJ50" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
~~~
References 
- Z. Wu, S. Cheng, P. Zhao, et al. $\mathcal L_1$Quad: $\mathcal L_1$ adaptive augmentation of geometric control for agile quadrotors with performance guarantees. In preparation, 2022.
- Z. Wu, C. Sheng, K. A. Ackerman, A. Gahlawat, A. Lakshmanan, P. Zhao, and N. Hovakimyan.  $\mathcal L_1$ adaptive augmentation for geometric tracking control of quadrotors. /IEEE International Conference on Robotics and Automation/, pp. 1329 – 1336, 2022.

== Adaptive control with switched or scheduled desired dynamics with aerospace applications
Motivated by the need to adjust the desired dynamics in the control of aerospace systems, we developed adaptive controllers that allow the desired dynamics to be systematically scheduled or switched, e.g., according to the operating conditions. The developed adaptive controllers utilize the $\mathcal L_1$ adaptive control architecture that has been tested on many safety-critical systems, including piloted and unmanned aircraft, and incorporate LPV and switching systems to characterize the desired dynamics.  
In particular, for LPV systems subject to unmatched uncertainties,  we proposed a novel approach based on peak-to-peak gain minimization and analysis from robust control to mitigate the effect of unmatched uncertainties, while allowing for the controllers to provide transient performance guarantees. Additionally, the adaptive controller with switched desired dynamics was used to facilitate safe real-time learning of aerial vehicle dynamics and tested on a UAV. 
~~~
{}{raw}
<iframe width="560" height="315" src="https://www.youtube.com/embed/y6O1mwzHdOE" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
~~~
References 
- S. Snyder, P. Zhao and N. Hovakimyan. $\mathcal L_1$ adaptive control with switched reference models: Application to Learn-to-Fly. /Journal of Guidance, Control, and Dynamics/, in press, 2022. 
- P. Zhao, S. Snyder, N. Hovakimyan and C. Cao. Robust adaptive control of linear parameter-varying systems with unmatched uncertainties. Submitted, 2021. arXiv:2010.04600.
- S. Snyder, P. Zhao and N. Hovakimyan. L1 adaptive control for switching reference systems: Application to flight control. /IFAC-PapersOnLine/, 52(16), pp.718-723, 2019.


== Intelligent agricultural management with reinforcement learning and crop simulations
The world’s agricultural system is facing significant challenges to bridge the gap between the amount of food produced today and that needed to feed a population of 9.6 billion by 2050 while reducing environmental impacts. In this project, we envisioned an intelligent agricultural management system based on deep reinforcement learning (RL) and crop simulations (e.g., using DSSAT), which can improve crop yields while reducing the use of resources (e.g., fertilizers, irrigation water) compared to expert-suggested management practices. We also leveraged imitation learning (IL) to train practically-implementable management policies that use only the state information that is easily accessible in the real world. 
~~~
{}{img_left}{https://github.com/boranzhao/boranzhao.github.io/blob/main/figs/carbon-rl.png?raw=true}{Agricultural managment via RL, imitation learning and crop simulations}{600}{}{https://github.com/boranzhao/boranzhao.github.io/blob/main/figs/carbon-rl.png?raw=true}
~~~
References
- J. Wu\*, R. Tao\*, P. Zhao\*, N. Martin and N. Hovakimyan. Optimizing nitrogen management with deep reinforcement learning and
crop simulations. /IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops/, pp. 1712-1720, 2022. 
- Ran Tao, Pan Zhao, Jing Wu, et al. Optimizing Crop management with reinforcement learning and imitation learning. Submitted, 2022.


== Robust and optimal switching linear parameter-varying (LPV) control 
Real-world mechatronic, aerospace and robotic systems often have complex nonlinear and/or time-varying dynamics. Control design for such systems needs to consider these complex dynamics to ensure stability and performance. Linear parameter-varying (LPV) control provides a systematic and easy-to-implement way for gain-scheduled control of nonlinear and/or time-varying systems. 
To deal with large dynamics variation, switching LPV control has also been proposed for reducing the conservativeness of LPV control. In practice, the scheduling parameters (e.g., wind speed for a wind turbine system) are often measured with errors, and ignoring such errors in controller design could lead to degraded performance or even loss of stability. We proposed an approach to designing switching LPV controllers with stability and performance guarantees despite measurement errors in scheduling parameters. We also developed methods to optimally design a switching LPV controller’s switching surfaces for improved performance. These methods were applied to control an automotive engine and a floating wind turbine.  
~~~
{}{img_left}{https://github.com/boranzhao/boranzhao.github.io/blob/main/figs/slpv.jpg?raw=true}{alt text}{560}{}{https://github.com/boranzhao/boranzhao.github.io/blob/main/figs/slpv.jpg?raw=true}
~~~
References 
- P. Zhao and R. Nagamune. Switching LPV controller design under uncertain scheduling parameters. Automatica, 76: 243–250, 2017.
- P. Zhao and R. Nagamune. Switching linear parameter-varying control with improved local performance and optimized switching surfaces. /International Journal of Robust and Nonlinear Control/, 28: 3403–3421, 2018.
- P. Zhao and R. Nagamune. Optimal switching surface design for state-feedback switching LPV control. /American Control Conference/, pp. 817–822, 2015. 
- P. Zhao and R. Nagamune. Optimal switching surface design for switching LPV control and its application to air-fuel ratio control of an automotive engine. /IEEE Conference on Control Technology and Applications (CCTA)/, pp. 898–903, 2017.
- P. Zhao and R. Nagamune. Switching LPV control of a floating offshore wind turbine on a semi-submersible platform. /IEEE 28th International Symposium on Industrial Electronics/, pp. 664-669, 2019.
- P. Zhao and R. Nagamune. Discrete-time state-feedback switching LPV Control with seperate Lyapunov functions for stability and local performance. /American Control Conference/, pp. 2023–2028, 2018.


== Robust and gain-scheduled control of miniaturized optical image stabilizers (OISs)
In this project,  we developed robust and gain-scheduled controllers for miniaturized optical image stabilizers to deal with the inevitable product variations that induce dynamics change across different products. The controllers were experimentally validated on both large-scale and small-scale prototypes. 
~~~
{}{img_left}{https://github.com/boranzhao/boranzhao.github.io/blob/main/figs/OIS-ExpSetup.png?raw=true}{Experimental setup with the large-scale prototype}{560}{345}{https://github.com/boranzhao/boranzhao.github.io/blob/main/figs/OIS-ExpSetup.png?raw=true}
~~~

References
- A. Alizadegan, P. Zhao, R. Nagamune and M. Chiao. Experimental validation of a robust $H_\infty$ control method on miniaturized optical image stabilizer prototypes. /Journal of Dynamic Systems, Measurement, and Control/, 142(12): 124501, 2020. 
- P. Zhao, R. Nagamune and M. Chiao. Multiple parameter-dependent robust control of miniaturized optical image stabilizers. /Control Engineering Practice/, 2018, 76: 1–11. 
- A. Alizadegan, P. Zhao, R. Nagamune and M. Chiao. Robust $H_\infty$ control of miniaturized optical image stabilizers against product variabilities. /Control Engineering Practice/, 80: 70–82, 2018. 
- P. Zhao, A. Alizadegan, R. Nagamune and M. Chiao. Robust control of large-scale prototypes for miniaturized optical image stabilizers with product variations. /SICE Annual Conference/, pp. 925–930, 2015. 


