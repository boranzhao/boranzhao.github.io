<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico" />
<title>Selected Projects</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Pan Zhao</div>
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-item"><a href="research.html" class="current">Research</a></div>
<div class="menu-item"><a href="publication.html">Publications</a></div>
<div class="menu-item"><a href="experience.html">Experience</a></div>
<div class="menu-item"><a href="teaching.html">Teaching</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Selected Projects</h1>
</div>
<h2>Adaptive control for Learn-to-Fly</h2>
<p>Learn-to-Fly  aims to reduce or eliminate the need for ground-based aero-dynamic modeling in favor of in-flight modeling and control law determination. At the initial stage of the model learning process, large uncertainties inevitably exist. To stabilize the aerial vehicles in the presence of the large uncertainties, we leverage and extend the <img class="eq" src="eqs/231873739-130.png" alt="mathcal{L}_1" style="vertical-align: -3px" /> adaptive control architecture to allow for switched nominal/desired dynamics, as a result of periodic update of the learned model. The framework is validated by flight tests on UAVs.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/CeaOeFUCxVc" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<p>References </p>
<ul>
<li><p>S. Snyder, <b>P. Zhao</b>* and N. Hovakimyan.  Adaptive control for Learn-to-Fly validated by flight tests, <i>in preparation</i>.</p>
</li>
</ul>
<h2>Robust and gain-scheduled control of miniaturized optical image stabilizers (OISs)</h2>
<p>In this project, robust and gain-scheduled control methods are explored for miniaturized optical image stabilizers to deal with the inevitable product variations. These methods were experimentally validated on both large-scale and small-scale prototypes. </p>
<table class="imgtable"><tr><td>
<a href="https://github.com/boranzhao/boranzhao.github.io/blob/main/figs/OIS-ExpSetup.png?raw=true"><img src="https://github.com/boranzhao/boranzhao.github.io/blob/main/figs/OIS-ExpSetup.png?raw=true" alt="Experimental setup with the large-scale prototype" width="560px" height="345px" /></a>&nbsp;</td>
<td align="left"></td></tr></table>
<ul>
<li><p>A. Alizadegan, P. Zhao, R. Nagamune and M. Chiao. Experimental validation of a robust <img class="eq" src="eqs/1019227541-130.png" alt="H_infty" style="vertical-align: -4px" /> control method on miniaturized optical image stabilizer prototypes. <i>Journal of Dynamic Systems, Measurement, and Control</i>, 142(12): 124501, 2020. </p>
</li>
<li><p>P. Zhao, R. Nagamune and M. Chiao. Multiple parameter-dependent robust control of minia- turized optical image stabilizers. <i>Control Engineering Practice</i>, 2018, 76: 1–11. </p>
</li>
<li><p>A. Alizadegan, P. Zhao, R. Nagamune and M. Chiao. Robust <img class="eq" src="eqs/1019227541-130.png" alt="H_infty" style="vertical-align: -4px" /> control of miniaturized optical image stabilizers against product variabilities. <i>Control Engineering Practice</i>, 80: 70–82, 2018. </p>
</li>
<li><p>P. Zhao, A. Alizadegan, R. Nagamune and M. Chiao. Robust control of large-scale prototypes for miniaturized optical image stabilizers with product variations. <i>Proceedings of SICE Annual Conference</i>, pp. 925–930, 2015. </p>
</li>
</ul>
<h2>Otimizing take-over requests in automated vehicles using reinforcement learning</h2>
<p>For automated vehicles with Level 3 automation, a driver stills need to take over control of the vehicles when there are some critical situations beyond the capacity of the autonomous driving system. In such cases, a take-over request (TOR) should be issued to alert the driver.  
To accommodate the differences among drivers e.g. in response time and driving preferences, we explored applying reinforcement learning to improve the TOR so that the false alarm rate can be guaranteed.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/wOR_Y-YX9oQ" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<div id="footer">
<div id="footer-text">
Page generated 2021-01-01 14:33:15 Central Standard Time, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
